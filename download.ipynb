{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_z3DlnC0y-I",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Download Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGaRIx2105Na",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from json import loads as parse_json\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Changing the option to show a dataframe not 'in-line'\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Gxc1CC5vCod",
    "outputId": "518ed245-2158-4a81-8e99-f05f23ec518c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.idea', 'venv', 'image_resizer.py', 'Downloading_Script_old.ipynb', 'Data_Probing_and_Cleaning_Script.ipynb', 'group_images.py', 'download.ipynb', 'links.csv', 'images']\n",
      "links.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dir = os.listdir()\n",
    "print(dir)\n",
    "\n",
    "csv_file = [i for i in dir if '.csv' in i][0]\n",
    "print(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1svgtrI07ov",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reading Query Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZIDOXTrGuvaf",
    "outputId": "7deedd26-b5b5-46a5-aa8f-624dd4dad22d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of query:  (0, 0)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'multimedia.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShape of query: \u001B[39m\u001B[38;5;124m\"\u001B[39m, query\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# print(query.sort_values('numberOfOccurrences'))\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m media \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmultimedia.txt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\t\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlatin-1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mobject\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon_bad_lines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mskip\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdropna(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# uses gbifID for 'occurrence'\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShape of media: \u001B[39m\u001B[38;5;124m\"\u001B[39m, media\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m     14\u001B[0m occur \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moccurrence.txt\u001B[39m\u001B[38;5;124m'\u001B[39m, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatin-1\u001B[39m\u001B[38;5;124m'\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mobject\u001B[39m, on_bad_lines\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mskip\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mdropna(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# uses taxonKey for 'class' and gbifIF for 'occurrence'\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/GBIF/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[0;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/GBIF/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/GBIF/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    947\u001B[0m )\n\u001B[1;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/GBIF/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    602\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    604\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 605\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/Desktop/GBIF/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/GBIF/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1733\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1734\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1735\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1737\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1738\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1739\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1740\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1741\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1742\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1743\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1744\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/Desktop/GBIF/venv/lib/python3.10/site-packages/pandas/io/common.py:856\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    851\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    852\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    854\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    855\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 856\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    863\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    864\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    865\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'multimedia.txt'"
     ]
    }
   ],
   "source": [
    "# Loading CSVs from google drive\n",
    "try:\n",
    "    query = pd.read_csv(csv_file, sep=',', encoding='latin-1', dtype=object).dropna(axis=1, how='all') # uses taxonKey for 'class'\n",
    "except:\n",
    "    query = pd.read_csv(csv_file, sep='\\t', encoding='latin-1', dtype=object).dropna(axis=1, how='all') # uses taxonKey for 'class'\n",
    "\n",
    "\n",
    "print(\"Shape of query: \", query.shape)\n",
    "# print(query.sort_values('numberOfOccurrences'))\n",
    "\n",
    "media = pd.read_csv('multimedia.txt', sep='\\t', encoding='latin-1', dtype=object, on_bad_lines='skip').dropna(axis=1, how='all') # uses gbifID for 'occurrence'\n",
    "print(\"Shape of media: \", media.shape)\n",
    "\n",
    "occur = pd.read_csv('occurrence.txt', sep='\\t', encoding='latin-1', dtype=object, on_bad_lines='skip').dropna(axis=1, how='all') # uses taxonKey for 'class' and gbifIF for 'occurrence'\n",
    "print(\"Shape of occur: \", occur.shape)\n",
    "\n",
    "# unique taxons\n",
    "occur_count = occur.nunique()\n",
    "media_count = media.nunique()\n",
    "print('unique ids in occur: ', occur_count[\"gbifID\"])\n",
    "print('unique ids in media: ', media_count[\"gbifID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1de7u871GKJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Managing the Loaded Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67Amqrvv0GM2",
    "outputId": "0622511a-7c83-4e28-d229-82c7717f9362",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of occur_media:  (1468010, 213)\n",
      "<bound method NDFrame.head of 0          https://inaturalist-open-data.s3.amazonaws.com...\n",
      "1          https://inaturalist-open-data.s3.amazonaws.com...\n",
      "2          https://inaturalist-open-data.s3.amazonaws.com...\n",
      "3          https://inaturalist-open-data.s3.amazonaws.com...\n",
      "4          https://inaturalist-open-data.s3.amazonaws.com...\n",
      "                                 ...                        \n",
      "1468005    https://svampe.databasen.org/uploads/2022-1027...\n",
      "1468006    https://svampe.databasen.org/uploads/2022-1027...\n",
      "1468007    https://svampe.databasen.org/uploads/2022-1027...\n",
      "1468008    https://svampe.databasen.org/uploads/2022-1027...\n",
      "1468009    http://specify.ugrasu.ru:8080/fileget?coll=Fun...\n",
      "Name: identifier_y, Length: 1468010, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "# combine the dataframes based on matching id\n",
    "occur_media = pd.merge(occur, media, on=\"gbifID\", how=\"inner\")\n",
    "\n",
    "print(\"Shape of occur_media: \", occur_media.shape)\n",
    "print(occur_media['identifier_y'].head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjJKIBeG0TCL",
    "outputId": "822b55d3-6767-48e2-a7c4-9985c83d1384",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     taxonKey          genus                   species numberOfOccurrences\n",
      "463  11571791   Sphaerobolus     Sphaerobolus ingoldii                 452\n",
      "194   5247390        Cerrena         Cerrena hydnoides                 357\n",
      "359   6124406       Clathrus        Clathrus crispatus                 254\n",
      "21   11892250       Astraeus         Astraeus morganii                 201\n",
      "111   5243168  Chlorophyllum  Chlorophyllum molybdites                 156\n",
      "..        ...            ...                       ...                 ...\n",
      "292  11463094   Xerocomellus      Xerocomellus bolinii                   1\n",
      "294   2520705      Phellinus       Phellinus fastuosus                   1\n",
      "296   3359489        Russula           Russula vinacea                   1\n",
      "304   5244501       Clavaria         Clavaria fragilis                   1\n",
      "258   7351381    Auricularia     Auricularia nigricans                   1\n",
      "\n",
      "[385 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bulld\\AppData\\Local\\Temp\\ipykernel_18808\\1976546659.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  taxons = query.iloc[sort_order][query['numberOfOccurrences'].astype('int32') > 0][::-1].dropna(subset=['species'])\n"
     ]
    }
   ],
   "source": [
    "# sort using the values as numbers, not objects/strings\n",
    "sort_order = query['numberOfOccurrences'].astype('int32').argsort() \n",
    "\n",
    "# sort the queries by occurence number and then reverse it because argsort is always ascending order\n",
    "taxons = query.iloc[sort_order][query['numberOfOccurrences'].astype('int32') > 0][::-1].dropna(subset=['species']) \n",
    "\n",
    "print(taxons[['taxonKey','genus', 'species', 'numberOfOccurrences']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX609q5d1Ylb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generating Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8Qxzigk0Ua0",
    "outputId": "f3940ac3-1f80-4993-f1c7-a515c25fae15",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Species\t 40.0\n",
      "Number of rows:\t 32000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_images = 800\n",
    "max_species = 40 # number of species without enough images\n",
    "cur_species_count = 0\n",
    "# initialize the empty dataframe\n",
    "links = pd.DataFrame(columns=['key',  'species', 'link'])\n",
    "\n",
    "# loop through and grab n rows per taxon\n",
    "for i in range(len(taxons)):\n",
    "    \n",
    "    if cur_species_count >= max_species:\n",
    "        break \n",
    "\n",
    "    # subset occurences to get just the first n matching rows\n",
    "    current_taxon = taxons['taxonKey'].iloc[i]\n",
    "    subset = occur_media.loc[occur_media['taxonKey'] == current_taxon].dropna(subset=['identifier_y'])\n",
    "\n",
    "    # initialize a (n, 3) array to fill\n",
    "    arr = np.ndarray((number_of_images, 3), dtype='object')\n",
    "    count = 0\n",
    "\n",
    "    if len(subset) > number_of_images:\n",
    "        for j in range(len(subset)):\n",
    "\n",
    "            # get the file extension \n",
    "            url = subset.iloc[j]['identifier_y']\n",
    "            root, ext = os.path.splitext(url)\n",
    "\n",
    "            # filter out any files that dont have .jpg or .jpeg extensions for uniformity\n",
    "            if ext == '.jpg' or ext == '.jpeg':\n",
    "                \n",
    "                # take the useful values from the current row and insert them into the ndarray\n",
    "                row = subset.iloc[j][['taxonKey', 'species', 'identifier_y']]\n",
    "                arr[count] = [row['taxonKey'], row['species'], row['identifier_y']]\n",
    "                count += 1\n",
    "\n",
    "            # filled array\n",
    "            if count >= number_of_images:\n",
    "                count = 0\n",
    "                break\n",
    "\n",
    "        # convert the filled ndarray into a dataframe \n",
    "        sub = pd.DataFrame(arr, columns=['key',  'species', 'link'])\n",
    "\n",
    "        # concatenate the dataframe\n",
    "        links = pd.concat([links, sub])\n",
    "        \n",
    "        cur_species_count += 1\n",
    "        \n",
    "\n",
    "# reset and drop the indices        \n",
    "links = links.reset_index()[['key',  'species', 'link']]\n",
    "\n",
    "print('Number of Species\\t', links.shape[0] / number_of_images)\n",
    "print('Number of rows:\\t', links.shape[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PuoZOXDI0dOc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run this to redownload the aggregated links file\n",
    "links.to_csv('links.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQswm8sr1j4j",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reading from Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this is a checkpoint\n",
    "links = pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Xcrl2Ap0ojO",
    "outputId": "1992805f-688a-45e7-e70c-525201a44cbd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique keys:\t 1\n",
      "Unique species:\t 1 \n",
      "\n",
      "species         \n",
      "Pholiota adiposa    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "IDs for duplicate species (\"Laetiporus sulphureus\"):  []\n",
      "\n",
      "\n",
      "After Removal:\n",
      "\n",
      "IDs for duplicate species (\"Laetiporus sulphureus\"):  []\n",
      "\n",
      "Unique keys:\t 1\n",
      "Unique species:\t 1\n"
     ]
    }
   ],
   "source": [
    "nkeys = links['key'].value_counts()\n",
    "print('Unique keys:\\t', len(nkeys))\n",
    "\n",
    "nspecies = links['species'].value_counts()\n",
    "print('Unique species:\\t', len(nspecies), '\\n')\n",
    "\n",
    "keys_species = links.groupby(['key','species']).size().reset_index().rename(columns={0:'count'})\n",
    "print(keys_species[['species']].value_counts().sort_values().tail())\n",
    "\n",
    "print('\\nIDs for duplicate species (\"Laetiporus sulphureus\"): ', links[links['species'] == 'Laetiporus sulphureus']['key'].unique())\n",
    "\n",
    "links = links[links['key'] != '2542235']\n",
    "\n",
    "print('\\n\\nAfter Removal:')\n",
    "print('\\nIDs for duplicate species (\"Laetiporus sulphureus\"): ', links[links['species'] == 'Laetiporus sulphureus']['key'].unique())\n",
    "\n",
    "nkeys = links['key'].value_counts()\n",
    "print('\\nUnique keys:\\t', len(nkeys))\n",
    "\n",
    "nspecies = links['species'].value_counts()\n",
    "print('Unique species:\\t', len(nspecies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2YO0lVr1qev",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Downloading the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "u-cxpojB0pxB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.idea', 'download.ipynb', 'Downloading_Script_old.ipynb', 'group_images.py', 'image_resizer.py', 'image_square.py', 'links.csv', 'venv']\n"
     ]
    }
   ],
   "source": [
    "dir = os.listdir()\n",
    "print(dir)\n",
    "if 'images' not in dir:\n",
    "    os.mkdir('images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E-SCELZn0tUL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pholiota_adiposa\n"
     ]
    }
   ],
   "source": [
    "for key in links['key'].unique():\n",
    "    subset = links[links['key'] == key]\n",
    "    output_dir = 'images/'\n",
    "    count = 0\n",
    "    species_name = subset['species'].unique()[0].replace(' ', '_')\n",
    "\n",
    "    print(species_name)\n",
    "\n",
    "    # print(subset)\n",
    "\n",
    "    for link in links[links['key'] == key]['link']:\n",
    "        try:\n",
    "            image = requests.get(link).content\n",
    "            output_file = os.path.join(output_dir, species_name + '_' + str(count) + '.jpg')\n",
    "            # print(output_file)\n",
    "            with open(output_file, 'wb') as writer:\n",
    "                writer.write(image)\n",
    "\n",
    "            # FILE.download(output_file)\n",
    "\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "        \n",
    "        finally:\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2:11\n",
      "Ended at  20:23:06\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "print('Started at 8:05')\n",
    "print(\"Ended at \", current_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}